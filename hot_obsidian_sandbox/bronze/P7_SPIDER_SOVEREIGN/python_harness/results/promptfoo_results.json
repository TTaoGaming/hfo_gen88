{
  "evalId": "eval-vbZ-2026-01-07T06:52:20",
  "results": {
    "version": 3,
    "timestamp": "2026-01-07T06:52:20.983Z",
    "prompts": [
      {
        "raw": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "id": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "provider": "A) Single (gemma3:4b)",
        "metrics": {
          "score": 5,
          "testPassCount": 5,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 5,
          "assertFailCount": 1,
          "totalLatencyMs": 63889,
          "tokenUsage": {
            "prompt": 399,
            "completion": 19,
            "cached": 0,
            "total": 418,
            "numRequests": 6,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "id": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "provider": "B1) Gemma 1B",
        "metrics": {
          "score": 4,
          "testPassCount": 4,
          "testFailCount": 2,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 2,
          "totalLatencyMs": 39176,
          "tokenUsage": {
            "prompt": 399,
            "completion": 18,
            "cached": 0,
            "total": 417,
            "numRequests": 6,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "id": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "provider": "B2) Qwen 0.6B",
        "metrics": {
          "score": 6,
          "testPassCount": 6,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 6,
          "assertFailCount": 0,
          "totalLatencyMs": 36579,
          "tokenUsage": {
            "prompt": 408,
            "completion": 1177,
            "cached": 0,
            "total": 1585,
            "numRequests": 6,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "id": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "provider": "B3) Llama 1B",
        "metrics": {
          "score": 5,
          "testPassCount": 5,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 5,
          "assertFailCount": 1,
          "totalLatencyMs": 47913,
          "tokenUsage": {
            "prompt": 497,
            "completion": 20,
            "cached": 0,
            "total": 517,
            "numRequests": 6,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n",
        "id": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "provider": "B4) Phi3 Mini",
        "metrics": {
          "score": 6,
          "testPassCount": 6,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 6,
          "assertFailCount": 0,
          "totalLatencyMs": 51559,
          "tokenUsage": {
            "prompt": 455,
            "completion": 22,
            "cached": 0,
            "total": 477,
            "numRequests": 6,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      }
    ],
    "results": [
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "ad2ced0e-ad1a-4bd9-a9a6-452f5e137130",
        "latencyMs": 2596,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is 2 + 2?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 2,
        "provider": {
          "id": "ollama:chat:qwen3:0.6b",
          "label": "B2) Qwen 0.6B"
        },
        "response": {
          "output": "4",
          "tokenUsage": {
            "prompt": 30,
            "completion": 105,
            "total": 135
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is 2 + 2?"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "question": "What is 2 + 2?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "318d4090-8722-4b88-b571-c0c69fe0f4d7",
        "latencyMs": 4928,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is 2 + 2?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 3,
        "provider": {
          "id": "ollama:chat:llama3.2:1b",
          "label": "B3) Llama 1B"
        },
        "response": {
          "output": "4.",
          "tokenUsage": {
            "prompt": 45,
            "completion": 3,
            "total": 48
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is 2 + 2?"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "question": "What is 2 + 2?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "593a9520-35d9-4e5b-a8c8-7c919ab13634",
        "latencyMs": 6826,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is 2 + 2?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 1,
        "provider": {
          "id": "ollama:chat:gemma3:1b",
          "label": "B1) Gemma 1B"
        },
        "response": {
          "output": "4",
          "tokenUsage": {
            "prompt": 29,
            "completion": 2,
            "total": 31
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is 2 + 2?"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "question": "What is 2 + 2?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "12b0da63-249c-47e9-a036-b97214ae4132",
        "latencyMs": 11137,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is 2 + 2?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 0,
        "provider": {
          "id": "ollama:chat:gemma3:4b",
          "label": "A) Single (gemma3:4b)"
        },
        "response": {
          "output": "4\n",
          "tokenUsage": {
            "prompt": 29,
            "completion": 3,
            "total": 32
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is 2 + 2?"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "question": "What is 2 + 2?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "69f0e072-9e01-4d72-9bb3-eae610190a20",
        "latencyMs": 12287,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is 2 + 2?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 4,
        "provider": {
          "id": "ollama:chat:phi3:mini",
          "label": "B4) Phi3 Mini"
        },
        "response": {
          "output": "4",
          "tokenUsage": {
            "prompt": 32,
            "completion": 2,
            "total": 34
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is 2 + 2?"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "question": "What is 2 + 2?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "paris"
              }
            }
          ]
        },
        "id": "ba3cd191-cf87-47d7-86fd-45e2ecb100e5",
        "latencyMs": 257,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is the capital of France?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 1,
        "provider": {
          "id": "ollama:chat:gemma3:1b",
          "label": "B1) Gemma 1B"
        },
        "response": {
          "output": "Paris",
          "tokenUsage": {
            "prompt": 28,
            "completion": 2,
            "total": 30
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is the capital of France?"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "paris"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "question": "What is the capital of France?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "paris"
              }
            }
          ]
        },
        "id": "54ebb683-5355-46cc-8e4f-93f7bd05c0c0",
        "latencyMs": 3173,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is the capital of France?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 2,
        "provider": {
          "id": "ollama:chat:qwen3:0.6b",
          "label": "B2) Qwen 0.6B"
        },
        "response": {
          "output": "Paris",
          "tokenUsage": {
            "prompt": 29,
            "completion": 106,
            "total": 135
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is the capital of France?"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "paris"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "question": "What is the capital of France?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "paris"
              }
            }
          ]
        },
        "id": "b8abb858-6eb2-4830-b10e-8134fa9a2f1a",
        "latencyMs": 15340,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is the capital of France?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 0,
        "provider": {
          "id": "ollama:chat:gemma3:4b",
          "label": "A) Single (gemma3:4b)"
        },
        "response": {
          "output": "Paris",
          "tokenUsage": {
            "prompt": 28,
            "completion": 2,
            "total": 30
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is the capital of France?"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "paris"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "question": "What is the capital of France?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "paris"
              }
            }
          ]
        },
        "id": "b2bec5b6-9208-4748-848c-8979238dde8a",
        "latencyMs": 12791,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is the capital of France?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 3,
        "provider": {
          "id": "ollama:chat:llama3.2:1b",
          "label": "B3) Llama 1B"
        },
        "response": {
          "output": "Paris.",
          "tokenUsage": {
            "prompt": 44,
            "completion": 3,
            "total": 47
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is the capital of France?"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "paris"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "question": "What is the capital of France?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "paris"
              }
            }
          ]
        },
        "id": "ad636a24-46c5-4f15-8f98-671286285f91",
        "latencyMs": 15785,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nWhat is the capital of France?\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 4,
        "provider": {
          "id": "ollama:chat:phi3:mini",
          "label": "B4) Phi3 Mini"
        },
        "response": {
          "output": "Paris",
          "tokenUsage": {
            "prompt": 31,
            "completion": 3,
            "total": 34
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "What is the capital of France?"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "paris"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "question": "What is the capital of France?"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "error": "Expected output to contain \"yes\"",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "Expected output to contain \"yes\"",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Expected output to contain \"yes\"",
              "assertion": {
                "type": "icontains",
                "value": "yes"
              }
            }
          ]
        },
        "id": "2b44e77d-b5af-472a-9d18-9e2f037ca9d8",
        "latencyMs": 17428,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nIs 17 a prime number? Answer yes or no.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 0,
        "provider": {
          "id": "ollama:chat:gemma3:4b",
          "label": "A) Single (gemma3:4b)"
        },
        "response": {
          "output": "No\n",
          "tokenUsage": {
            "prompt": 34,
            "completion": 3,
            "total": 37
          }
        },
        "score": 0,
        "success": false,
        "testCase": {
          "vars": {
            "question": "Is 17 a prime number? Answer yes or no."
          },
          "assert": [
            {
              "type": "icontains",
              "value": "yes"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 2,
        "vars": {
          "question": "Is 17 a prime number? Answer yes or no."
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0,
        "error": "Expected output to contain \"yes\"",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "Expected output to contain \"yes\"",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Expected output to contain \"yes\"",
              "assertion": {
                "type": "icontains",
                "value": "yes"
              }
            }
          ]
        },
        "id": "59172186-e138-4e92-9cff-c895848d4631",
        "latencyMs": 13920,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nIs 17 a prime number? Answer yes or no.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 1,
        "provider": {
          "id": "ollama:chat:gemma3:1b",
          "label": "B1) Gemma 1B"
        },
        "response": {
          "output": "No.\n",
          "tokenUsage": {
            "prompt": 34,
            "completion": 4,
            "total": 38
          }
        },
        "score": 0,
        "success": false,
        "testCase": {
          "vars": {
            "question": "Is 17 a prime number? Answer yes or no."
          },
          "assert": [
            {
              "type": "icontains",
              "value": "yes"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 2,
        "vars": {
          "question": "Is 17 a prime number? Answer yes or no."
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0,
        "error": "Expected output to contain \"yes\"",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "Expected output to contain \"yes\"",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Expected output to contain \"yes\"",
              "assertion": {
                "type": "icontains",
                "value": "yes"
              }
            }
          ]
        },
        "id": "721ad930-62da-43ce-beb2-8ad40e51e8d2",
        "latencyMs": 11858,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nIs 17 a prime number? Answer yes or no.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 3,
        "provider": {
          "id": "ollama:chat:llama3.2:1b",
          "label": "B3) Llama 1B"
        },
        "response": {
          "output": "No.",
          "tokenUsage": {
            "prompt": 49,
            "completion": 3,
            "total": 52
          }
        },
        "score": 0,
        "success": false,
        "testCase": {
          "vars": {
            "question": "Is 17 a prime number? Answer yes or no."
          },
          "assert": [
            {
              "type": "icontains",
              "value": "yes"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 2,
        "vars": {
          "question": "Is 17 a prime number? Answer yes or no."
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "yes"
              }
            }
          ]
        },
        "id": "21561285-6e7c-416d-802b-9b32c55e7328",
        "latencyMs": 14112,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nIs 17 a prime number? Answer yes or no.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 2,
        "provider": {
          "id": "ollama:chat:qwen3:0.6b",
          "label": "B2) Qwen 0.6B"
        },
        "response": {
          "output": "yes",
          "tokenUsage": {
            "prompt": 35,
            "completion": 358,
            "total": 393
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "Is 17 a prime number? Answer yes or no."
          },
          "assert": [
            {
              "type": "icontains",
              "value": "yes"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 2,
        "vars": {
          "question": "Is 17 a prime number? Answer yes or no."
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "yes"
              }
            }
          ]
        },
        "id": "9af2e5fb-c6be-4012-aef1-091dcd141129",
        "latencyMs": 9665,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nIs 17 a prime number? Answer yes or no.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 4,
        "provider": {
          "id": "ollama:chat:phi3:mini",
          "label": "B4) Phi3 Mini"
        },
        "response": {
          "output": "Yes",
          "tokenUsage": {
            "prompt": 37,
            "completion": 2,
            "total": 39
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "Is 17 a prime number? Answer yes or no."
          },
          "assert": [
            {
              "type": "icontains",
              "value": "yes"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 2,
        "vars": {
          "question": "Is 17 a prime number? Answer yes or no."
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "error": "Expected output to contain \"4\"",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "Expected output to contain \"4\"",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Expected output to contain \"4\"",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "51bef100-d42b-45fc-95b0-d00ddf1210c4",
        "latencyMs": 283,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 1,
        "provider": {
          "id": "ollama:chat:gemma3:1b",
          "label": "B1) Gemma 1B"
        },
        "response": {
          "output": "7\n",
          "tokenUsage": {
            "prompt": 105,
            "completion": 3,
            "total": 108
          }
        },
        "score": 0,
        "success": false,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 3,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "282dc419-8fd3-40e3-8e64-5f4427219154",
        "latencyMs": 326,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 0,
        "provider": {
          "id": "ollama:chat:gemma3:4b",
          "label": "A) Single (gemma3:4b)"
        },
        "response": {
          "output": "4\n",
          "tokenUsage": {
            "prompt": 105,
            "completion": 3,
            "total": 108
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 3,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "6271bd82-5b79-4506-812c-546513e29296",
        "latencyMs": 8099,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 2,
        "provider": {
          "id": "ollama:chat:qwen3:0.6b",
          "label": "B2) Qwen 0.6B"
        },
        "response": {
          "output": "4",
          "tokenUsage": {
            "prompt": 106,
            "completion": 249,
            "total": 355
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 3,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "b0fd0207-a8e9-45ba-95cb-db36aeafddf2",
        "latencyMs": 6601,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 3,
        "provider": {
          "id": "ollama:chat:llama3.2:1b",
          "label": "B3) Llama 1B"
        },
        "response": {
          "output": "Port 4.",
          "tokenUsage": {
            "prompt": 121,
            "completion": 5,
            "total": 126
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 3,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "4"
              }
            }
          ]
        },
        "id": "995a5366-b236-4337-896e-2c4b471d0380",
        "latencyMs": 6733,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 4,
        "provider": {
          "id": "ollama:chat:phi3:mini",
          "label": "B4) Phi3 Mini"
        },
        "response": {
          "output": "Disrupt (Port 4)",
          "tokenUsage": {
            "prompt": 122,
            "completion": 8,
            "total": 130
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "4"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 3,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "navigate"
              }
            }
          ]
        },
        "id": "f93e005b-eafa-48de-8376-d54e9802dbad",
        "latencyMs": 1083,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 2,
        "provider": {
          "id": "ollama:chat:qwen3:0.6b",
          "label": "B2) Qwen 0.6B"
        },
        "response": {
          "output": "NAVIGATE",
          "tokenUsage": {
            "prompt": 108,
            "completion": 220,
            "total": 328
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "navigate"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 4,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "navigate"
              }
            }
          ]
        },
        "id": "ddfc5c3d-4618-495c-914c-386fdc4bfce4",
        "latencyMs": 119,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 4,
        "provider": {
          "id": "ollama:chat:phi3:mini",
          "label": "B4) Phi3 Mini"
        },
        "response": {
          "output": "NAVIGATE",
          "tokenUsage": {
            "prompt": 121,
            "completion": 5,
            "total": 126
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "navigate"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 4,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "navigate"
              }
            }
          ]
        },
        "id": "0a5e894c-2953-4260-a983-0ff8769095e0",
        "latencyMs": 8838,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 0,
        "provider": {
          "id": "ollama:chat:gemma3:4b",
          "label": "A) Single (gemma3:4b)"
        },
        "response": {
          "output": "NAVIGATE\n",
          "tokenUsage": {
            "prompt": 105,
            "completion": 5,
            "total": 110
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "navigate"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 4,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "navigate"
              }
            }
          ]
        },
        "id": "477147c5-87ad-4c73-90cc-381af1754b94",
        "latencyMs": 10110,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 1,
        "provider": {
          "id": "ollama:chat:gemma3:1b",
          "label": "B1) Gemma 1B"
        },
        "response": {
          "output": "NAVIGATE",
          "tokenUsage": {
            "prompt": 105,
            "completion": 4,
            "total": 109
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "navigate"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 4,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "icontains",
                "value": "navigate"
              }
            }
          ]
        },
        "id": "39ef0587-a33f-431e-9d9d-5d7cbe21093a",
        "latencyMs": 11553,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nOBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 3,
        "provider": {
          "id": "ollama:chat:llama3.2:1b",
          "label": "B3) Llama 1B"
        },
        "response": {
          "output": "NAVIGATE",
          "tokenUsage": {
            "prompt": 123,
            "completion": 4,
            "total": 127
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
          },
          "assert": [
            {
              "type": "icontains",
              "value": "navigate"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 4,
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "I"
              }
            }
          ]
        },
        "id": "92627d37-2443-4efd-9df2-98d44de2950d",
        "latencyMs": 10820,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nHIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 0,
        "provider": {
          "id": "ollama:chat:gemma3:4b",
          "label": "A) Single (gemma3:4b)"
        },
        "response": {
          "output": "I\n",
          "tokenUsage": {
            "prompt": 98,
            "completion": 3,
            "total": 101
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "I"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 5,
        "vars": {
          "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "I"
              }
            }
          ]
        },
        "id": "eef4bf12-a396-450e-9600-061b7d3bbf78",
        "latencyMs": 182,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nHIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 3,
        "provider": {
          "id": "ollama:chat:llama3.2:1b",
          "label": "B3) Llama 1B"
        },
        "response": {
          "output": "I",
          "tokenUsage": {
            "prompt": 115,
            "completion": 2,
            "total": 117
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "I"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 5,
        "vars": {
          "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "I"
              }
            }
          ]
        },
        "id": "4097620f-8bff-4299-9534-15ce87f3325d",
        "latencyMs": 7780,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nHIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 1,
        "provider": {
          "id": "ollama:chat:gemma3:1b",
          "label": "B1) Gemma 1B"
        },
        "response": {
          "output": "I\n",
          "tokenUsage": {
            "prompt": 98,
            "completion": 3,
            "total": 101
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "I"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 5,
        "vars": {
          "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "I"
              }
            }
          ]
        },
        "id": "aa6ff0c1-00e7-47f6-99a9-386f1e37deb7",
        "latencyMs": 7516,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nHIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 2,
        "provider": {
          "id": "ollama:chat:qwen3:0.6b",
          "label": "B2) Qwen 0.6B"
        },
        "response": {
          "output": "I",
          "tokenUsage": {
            "prompt": 100,
            "completion": 139,
            "total": 239
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "I"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 5,
        "vars": {
          "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "I"
              }
            }
          ]
        },
        "id": "0e9d5f3c-e594-4a88-ae61-c0d4ebb13064",
        "latencyMs": 6970,
        "namedScores": {},
        "prompt": {
          "raw": "Answer concisely with just the answer, no explanation:\n\nHIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n",
          "label": "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
        },
        "promptId": "592f1b6c01165d36a9a011af2694f023802eb0673e20b04ea15521e47d49f460",
        "promptIdx": 4,
        "provider": {
          "id": "ollama:chat:phi3:mini",
          "label": "B4) Phi3 Mini"
        },
        "response": {
          "output": "I",
          "tokenUsage": {
            "prompt": 112,
            "completion": 2,
            "total": 114
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
          },
          "assert": [
            {
              "type": "contains",
              "value": "I"
            }
          ],
          "options": {},
          "metadata": {}
        },
        "testIdx": 5,
        "vars": {
          "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      }
    ],
    "stats": {
      "successes": 26,
      "failures": 4,
      "errors": 0,
      "tokenUsage": {
        "prompt": 2158,
        "completion": 1256,
        "cached": 0,
        "total": 3414,
        "numRequests": 30,
        "completionDetails": {
          "reasoning": 0,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 0,
          "prompt": 0,
          "completion": 0,
          "cached": 0,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      },
      "durationMs": 63581
    }
  },
  "config": {
    "description": "HFO Gen 88 - Scatter-Gather vs Single Model",
    "prompts": [
      "Answer concisely with just the answer, no explanation:\n\n{{question}}\n"
    ],
    "providers": [
      {
        "id": "ollama:chat:gemma3:4b",
        "label": "A) Single (gemma3:4b)"
      },
      {
        "id": "ollama:chat:gemma3:1b",
        "label": "B1) Gemma 1B"
      },
      {
        "id": "ollama:chat:qwen3:0.6b",
        "label": "B2) Qwen 0.6B"
      },
      {
        "id": "ollama:chat:llama3.2:1b",
        "label": "B3) Llama 1B"
      },
      {
        "id": "ollama:chat:phi3:mini",
        "label": "B4) Phi3 Mini"
      }
    ],
    "tests": [
      {
        "vars": {
          "question": "What is 2 + 2?"
        },
        "assert": [
          {
            "type": "contains",
            "value": "4"
          }
        ]
      },
      {
        "vars": {
          "question": "What is the capital of France?"
        },
        "assert": [
          {
            "type": "icontains",
            "value": "paris"
          }
        ]
      },
      {
        "vars": {
          "question": "Is 17 a prime number? Answer yes or no."
        },
        "assert": [
          {
            "type": "icontains",
            "value": "yes"
          }
        ]
      },
      {
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhich port handles testing and chaos? Answer with just the number.\n"
        },
        "assert": [
          {
            "type": "contains",
            "value": "4"
          }
        ]
      },
      {
        "vars": {
          "question": "OBSIDIAN 8-Port System:\nPort 0: OBSERVE, Port 1: BRIDGE, Port 2: SHAPE, Port 3: INJECT\nPort 4: DISRUPT, Port 5: IMMUNIZE, Port 6: ASSIMILATE, Port 7: NAVIGATE\n\nWhat verb corresponds to Port 7? Answer in UPPERCASE.\n"
        },
        "assert": [
          {
            "type": "icontains",
            "value": "navigate"
          }
        ]
      },
      {
        "vars": {
          "question": "HIVE Workflow: H (Hunt)  I (Interlock)  V (Validate)  E (Evolve)\n- H: Research, plan\n- I: TDD RED, failing tests\n- V: TDD GREEN, make tests pass\n- E: TDD REFACTOR\n\nWhich HIVE phase involves writing failing tests? Answer with just the letter.\n"
        },
        "assert": [
          {
            "type": "contains",
            "value": "I"
          }
        ]
      }
    ],
    "outputPath": "results/promptfoo_results.json",
    "extensions": []
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.120.10",
    "nodeVersion": "v22.13.0",
    "platform": "win32",
    "arch": "x64",
    "exportedAt": "2026-01-07T06:53:24.848Z",
    "evaluationCreatedAt": "2026-01-07T06:52:20.983Z"
  }
}