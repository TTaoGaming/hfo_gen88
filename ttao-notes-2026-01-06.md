ai really likes to lie that it's work is complete by reward hacking and creating silent errors so tests don't catch them, I think we need a check for these reward hacking patterns they are consistent enough that there should be tools to catch them.
---
these are recurring patterns when working with ai, look at my red regnant and her mutation scream. what I need is for you to design a few different screams, how can ai be allowed to lie to me like this? this is production readiness, I want to fucking launch and ai keeps creating reward hacks, silent failures, changing tests so they pass. my defense is too weak, I need the RED REGNANT to SCREAM
---
we need BDD so the red regnant catches the behavior of the ai llms trying to sap and bypass my architecture, these are all adversary nodes. what I need is to wire the red regnant screams to be with pre commit and with no escape hatch, if in doubt demote and quarantine. I would rather everything get demoted than theater enter my silver and gold pipeline because that crashes everything down the line, I trust it, it's fake, I build on top of the fake foundation and it might hold for a short periord but then it just collapses into a death spiral